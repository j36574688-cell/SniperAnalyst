import streamlit as st
import json
import math
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import glob
import os
import datetime
from typing import Dict, List, Tuple, Any, Optional
from functools import lru_cache
from scipy.special import logsumexp, gammaln
from scipy.optimize import minimize

# [V40.6] å®‰å…¨å°å…¥ Plotly
try:
    import plotly.express as px
    import plotly.graph_objects as go
    HAS_PLOTLY = True
except ImportError:
    HAS_PLOTLY = False

# [V38] Numba JIT åŠ é€Ÿ
try:
    from numba import njit, prange
    HAS_NUMBA = True
except ImportError:
    HAS_NUMBA = False
    def njit(fastmath=False, parallel=False):
        def decorator(func): return func
        return decorator
    def prange(n): return range(n)

# =========================
# 1. æ ¸å¿ƒæ•¸å­¸å·¥å…· (Kernel)
# =========================
EPS = 1e-15

@njit(fastmath=True)
def fast_log_factorial(n):
    if n < 0: return 0.0
    if n <= 20:
        res = 0.0
        for i in range(1, n + 1): res += math.log(i)
        return res
    return n * math.log(n) - n + 0.5 * math.log(2 * math.pi * n)

@njit(fastmath=True)
def poisson_logpmf_fast(k, lam):
    if lam <= 0: return 0.0 if k == 0 else -1e10
    return -lam + k * math.log(lam) - fast_log_factorial(k)

@njit(fastmath=True)
def biv_poisson_logpmf_fast(x, y, lam1, lam2, lam3):
    if lam3 <= 1e-9: return poisson_logpmf_fast(x, lam1) + poisson_logpmf_fast(y, lam2)
    base = -(lam1 + lam2 + lam3)
    max_val = -1e20
    terms = np.zeros(min(x, y) + 1)
    for k in range(min(x, y) + 1):
        t = base
        if x-k>0: t += (x-k)*math.log(lam1) - fast_log_factorial(x-k)
        if y-k>0: t += (y-k)*math.log(lam2) - fast_log_factorial(y-k)
        if k>0: t += k*math.log(lam3) - fast_log_factorial(k)
        terms[k] = t
        if t > max_val: max_val = t
    sum_exp = 0.0
    for i in range(len(terms)): sum_exp += math.exp(terms[i] - max_val)
    return max_val + math.log(sum_exp)

@njit(fastmath=True, parallel=True)
def compute_batch_nll(lh_arr, la_arr, h_arr, a_arr, lam3, rho, home_adv):
    nll = 0.0
    n = len(lh_arr)
    for i in prange(n):
        lh = lh_arr[i] * home_adv
        la = la_arr[i]
        h = h_arr[i]
        a = a_arr[i]
        l1 = max(0.01, lh - lam3)
        l2 = max(0.01, la - lam3)
        lp = biv_poisson_logpmf_fast(h, a, l1, l2, lam3)
        prob = math.exp(lp)
        if h==0 and a==0: prob *= (1 - lh*la*rho)
        elif h==0 and a==1: prob *= (1 + lh*rho)
        elif h==1 and a==0: prob *= (1 + la*rho)
        elif h==1 and a==1: prob *= (1 - rho)
        if prob > 1e-9: nll -= math.log(prob)
        else: nll -= math.log(1e-9)
    return nll

def get_true_implied_prob(odds_dict):
    inv = {k: 1.0/v if v>0 else 0.0 for k,v in odds_dict.items()}
    s = sum(inv.values())
    return {k: inv[k]/s if s>0 else 0.0 for k in odds_dict}

def calc_risk_adj_kelly(ev_percent, variance, risk_scale=0.5, prob=0.5):
    if variance<=0 or ev_percent<=0: return 0.0
    ev = ev_percent/100.0
    f = (ev / variance) * risk_scale
    cap = 0.5 if prob>=0.35 else 0.025
    return min(cap, max(0.0, f)) * 100

def calc_risk_metrics(prob, odds):
    if prob<=0 or prob>=1: return 0.0, 0.0
    win_p, lose_p = odds-1.0, -1.0
    ev = prob*win_p + (1-prob)*lose_p
    var = prob*(win_p**2) + (1-prob)*(lose_p**2) - (ev**2)
    sharpe = ev/math.sqrt(var) if var>0 else 0
    return var, sharpe

@st.cache_data
def get_matrix_cached(lh, la, max_g, nb_alpha):
    G = max_g
    M = np.zeros((G, G))
    for i in range(G):
        for j in range(G):
            p = math.exp(biv_poisson_logpmf_fast(i, j, lh, la, 0.0))
            M[i, j] = p
    return M / M.sum()

# =========================
# 2. å…¨æ™¯è¨˜æ†¶èˆ‡å¯¦æˆ°ç³»çµ±
# =========================
class RegimeMemory:
    def __init__(self, db_path="regime_db.json"):
        self.db_path = db_path
        self.default_db = {
            "Bore_Draw_Stalemate": { "name": "ğŸ›¡ï¸ é›™é‡éµæ¡¶", "roi": 0.219, "bets": 2150 }, 
            "Relegation_Dog": { "name": "ğŸ• ä¿ç´šå—è®“", "roi": 0.083, "bets": 1840 },
            "Fallen_Giant": { "name": "ğŸ“‰ è±ªé–€å´©ç›¤", "roi": -0.008, "bets": 920 },
            "Fortress_Home": { "name": "ğŸ° é­”é¬¼ä¸»å ´", "roi": -0.008, "bets": 3100 },
            "Title_MustWin_Home": { "name": "ğŸ† çˆ­å† å¿…å‹ç›¤", "roi": -0.063, "bets": 2450 },
            "MarketHype_Fav": { "name": "ğŸ”¥ å¤§ç†±å€’ç¶", "roi": -0.080, "bets": 1560 },
            "MidTable_Standard": { "name": "ğŸ˜ ä¸­æ¸¸ä¾‹è¡Œ", "roi": 0.000, "bets": 5000 }
        }
        self.history_db = self.load_db()

    def load_db(self) -> Dict:
        if os.path.exists(self.db_path):
            try:
                with open(self.db_path, 'r', encoding='utf-8') as f: return json.load(f)
            except: return self.default_db
        return self.default_db

    def analyze_scenario(self, lh, la, odds) -> str:
        h = odds.get("home", 2.0)
        if h < 1.30: return "MarketHype_Fav"
        if (lh+la) < 2.2: return "Bore_Draw_Stalemate"
        if h < 2.0: return "Fortress_Home"
        return "MidTable_Standard"

    def recall_experience(self, rid: str) -> Dict:
        return self.history_db.get(rid, {"name": "æœªçŸ¥", "roi": 0.0, "bets": 0})

    def calc_memory_penalty(self, roi: float) -> float:
        if roi < -0.05: return 0.7
        if roi > 0.05: return 1.1
        return 1.0

class PaperTradingSystem:
    def __init__(self, file_path="my_bets.csv"):
        self.file_path = file_path
        
    def load_bets(self):
        if os.path.exists(self.file_path):
            try:
                return pd.read_csv(self.file_path)
            except:
                return pd.DataFrame(columns=["Date", "Selection", "Odds", "Stake", "Result", "PnL"])
        return pd.DataFrame(columns=["Date", "Selection", "Odds", "Stake", "Result", "PnL"])
        
    def add_bet(self, selection, odds, stake):
        df = self.load_bets()
        new_row = pd.DataFrame([{
            "Date": datetime.datetime.now().strftime("%Y-%m-%d %H:%M"),
            "Selection": selection,
            "Odds": odds,
            "Stake": stake,
            "Result": "Pending",
            "PnL": 0.0
        }])
        df = pd.concat([df, new_row], ignore_index=True)
        df.to_csv(self.file_path, index=False)
        return True
    
    def save_bets(self, df):
        # è‡ªå‹•é‡æ–°è¨ˆç®— PnL
        for idx, row in df.iterrows():
            res = row['Result']
            stake = float(row['Stake'])
            odds = float(row['Odds'])
            if res == "Win": df.at[idx, 'PnL'] = stake * (odds - 1)
            elif res == "Lose": df.at[idx, 'PnL'] = -stake
            elif res == "Void": df.at[idx, 'PnL'] = 0.0
            else: df.at[idx, 'PnL'] = 0.0
        df.to_csv(self.file_path, index=False)
    
    def get_stats(self):
        df = self.load_bets()
        if df.empty: return 0, 0, 0
        total_bets = len(df)
        total_stake = df["Stake"].sum()
        total_pnl = df["PnL"].sum()
        return total_bets, total_stake, total_pnl

# =========================
# 3. åˆ†æå¼•æ“é‚è¼¯
# =========================
class SniperAnalystLogic:
    def __init__(self, json_data, max_g=9, nb_alpha=0.12, lam3=0.0, rho=-0.13, home_adv=1.15):
        self.data = json_data if isinstance(json_data, dict) else json.loads(json_data)
        self.h = self.data["home"]
        self.a = self.data["away"]
        self.market = self.data["market_data"]
        self.max_g = max_g
        self.nb_alpha = nb_alpha
        self.lam3, self.rho, self.home_adv = lam3, rho, home_adv
        self.memory = RegimeMemory()

    def calc_lambda(self):
        def att_def_w(team):
            xg, xga = team["offensive_stats"].get("xg_avg", 1.0), team["defensive_stats"].get("xga_avg", 1.0)
            trend = team["context_modifiers"].get("recent_form_trend", [0, 0, 0])
            w = np.array([0.1, 0.3, 0.6])
            form_factor = 1.0 + (np.dot(trend[-len(w):], w[-len(trend):]) * 0.1)
            return (0.3 * team["offensive_stats"]["goals_scored_avg"] + 0.7 * xg) * form_factor, \
                   (0.3 * team["defensive_stats"]["goals_conceded_avg"] + 0.7 * xga)

        lh_att, lh_def = att_def_w(self.h)
        la_att, la_def = att_def_w(self.a)
        strength_gap = (lh_att - la_att)
        crush_factor = 1.05 if strength_gap > 0.5 else 1.0
        
        lh = (lh_att * la_def / 1.35) * self.home_adv * crush_factor
        la = (la_att * lh_def / 1.35)
        
        if self.h["context_modifiers"].get("missing_key_defender"): lh *= 0.9 
        if self.h["context_modifiers"].get("missing_key_defender"): la *= 1.25
        if self.a["context_modifiers"].get("missing_key_defender"): lh *= 1.20
        
        return lh, la, True

    def build_matrix_v38(self, lh, la, use_biv=True, use_dc=True):
        G = self.max_g
        M = np.zeros((G, G))
        l3 = max(self.lam3, 0.001) if use_biv else 0.0
        l1, l2 = max(0.01, lh-l3), max(0.01, la-l3)
        
        for i in range(G):
            for j in range(G):
                M[i,j] = math.exp(biv_poisson_logpmf_fast(i, j, l1, l2, l3))
        
        if use_dc:
            rho = self.rho
            def tau(x, y):
                if x==0 and y==0: return 1 - lh*la*rho
                elif x==0 and y==1: return 1 + lh*rho
                elif x==1 and y==0: return 1 + la*rho
                elif x==1 and y==1: return 1 - rho
                return 1.0
            for i in range(2):
                for j in range(2): M[i,j] *= tau(i,j)
            
        M /= M.sum()
        
        imp = get_true_implied_prob(self.market["1x2_odds"])
        ph, pd, pa = float(np.sum(np.tril(M,-1))), float(np.sum(np.diag(M))), float(np.sum(np.triu(M,1)))
        
        w = 0.7 if abs(ph - imp["home"]) < 0.2 else 0.5
        th = w*ph + (1-w)*imp["home"]
        td = w*pd + (1-w)*imp["draw"]
        ta = w*pa + (1-w)*imp["away"]
        
        M_hybrid = M.copy()
        M_hybrid[np.tril_indices(G,-1)] *= (th/ph if ph>0 else 1)
        M_hybrid[np.diag_indices(G)] *= (td/pd if pd>0 else 1)
        M_hybrid[np.triu_indices(G,1)] *= (ta/pa if pa>0 else 1)
        M_hybrid /= M_hybrid.sum()
        
        return M_hybrid, {"model": {"home": ph, "draw": pd, "away": pa}, "market": imp, "hybrid": {"home": th, "draw": td, "away": ta}}

    def get_market_trend_bonus(self):
        bonus = {"home":0.0, "draw":0.0, "away":0.0}
        op, cu = self.market.get("opening_odds"), self.market.get("1x2_odds")
        if not op or not cu: return bonus
        for k in bonus:
            drop = max(0.0, (op[k] - cu[k]) / op[k])
            bonus[k] = min(3.0, drop * 30.0)
        return bonus

    def ah_ev(self, M, hcap, odds):
        q = int(round(hcap * 4))
        if q % 2 != 0: return 0.5 * self.ah_ev(M, (q+1)/4.0, odds) + 0.5 * self.ah_ev(M, (q-1)/4.0, odds)
        idx_diff = np.subtract.outer(np.arange(self.max_g), np.arange(self.max_g)) 
        payoff = np.select([idx_diff + hcap > 0.001, np.abs(idx_diff + hcap) <= 0.001], [odds-1, 0], default=-1)
        return np.sum(M * payoff) * 100

    def check_sensitivity(self, lh, la):
        M_stress = get_matrix_cached(lh, la + 0.3, self.max_g, self.nb_alpha)
        p_orig = float(np.sum(np.tril(get_matrix_cached(lh, la, self.max_g, self.nb_alpha), -1)))
        p_new = float(np.sum(np.tril(M_stress, -1)))
        drop = (p_orig - p_new) / p_orig if p_orig > 0 else 0
        return ("High" if drop > 0.15 else "Medium"), drop

    def calc_model_confidence(self, lh, la, diff, sens):
        score, reasons = 1.0, []
        if diff > 0.25: score *= 0.7; reasons.append(f"èˆ‡å¸‚å ´å·®ç•°éå¤§ ({diff:.1%})")
        if sens > 0.15: score *= 0.8; reasons.append("æ¨¡å‹å°é‹æ°£çƒæ•æ„Ÿ")
        if (lh + la) > 3.5: score *= 0.9; reasons.append("é«˜è®Šç•°é¢¨éšª (xG > 3.5)")
        return score, reasons

    def simulate_uncertainty(self, lh, la, base_ev):
        evs = []
        for _ in range(50):
            lh_s = lh * np.random.normal(1.0, 0.1)
            la_s = la * np.random.normal(1.0, 0.1)
            ratio = (lh_s - la_s) / (lh - la) if abs(lh - la) > 0.1 else 1.0
            evs.append(base_ev * ratio)
        return np.percentile(evs, 5), np.percentile(evs, 95)

    def run_monte_carlo_vectorized(self, M, sims=500000):
        rng = np.random.default_rng()
        flat = M.flatten(); flat /= flat.sum()
        cdf = np.cumsum(flat)
        idx = np.searchsorted(cdf, rng.random(sims))
        hg, ag = idx // M.shape[0], idx % M.shape[0]
        return np.sum(hg>ag)/sims, np.sum(hg==ag)/sims, np.sum(hg<ag)/sims, hg, ag

    def run_ce_importance_sampling(self, M, line, n_sims=20000):
        G = M.shape[0]
        i_idx, j_idx = np.indices((G,G))
        mu_h = np.sum(M * i_idx)
        mu_a = np.sum(M * j_idx)
        v_h, v_a = mu_h * 1.5, mu_a * 1.5
        rng = np.random.default_rng()
        sh = rng.poisson(v_h, n_sims)
        sa = rng.poisson(v_a, n_sims)
        log_w = (sh*(np.log(mu_h)-np.log(v_h)) - (mu_h-v_h)) + \
                (sa*(np.log(mu_a)-np.log(v_a)) - (mu_a-v_a))
        w = np.exp(log_w)
        est = np.sum(w * ((sh+sa)>line)) / n_sims
        return {"est": float(est)}

# =========================
# 4. è³‡æ–™è™•ç†å·¥å…· (V40.3 å¼·åŠ›è®€å–ç‰ˆ)
# =========================
def preprocess_uploaded_data(df: pd.DataFrame) -> pd.DataFrame:
    df.columns = [str(c).strip() for c in df.columns]
    col_map = {
        'hometeam': 'home', 'home': 'home', 'ht': 'home', 'team1': 'home',
        'awayteam': 'away', 'away': 'away', 'at': 'away', 'team2': 'away',
        'fthg': 'home_goals', 'hg': 'home_goals', 'homegoals': 'home_goals', 'score1': 'home_goals',
        'ftag': 'away_goals', 'ag': 'away_goals', 'awaygoals': 'away_goals', 'score2': 'away_goals',
        'div': 'div', 'date': 'date'
    }
    new_cols = {}
    for col in df.columns:
        c_lower = col.lower().replace(" ", "").replace("_", "")
        if c_lower in col_map: new_cols[col] = col_map[c_lower]
    df = df.rename(columns=new_cols)
    required = ['home', 'away', 'home_goals', 'away_goals']
    if any(c not in df.columns for c in required): return pd.DataFrame()
    if 'lh_pred' not in df.columns or 'la_pred' not in df.columns:
        avg_h = df['home_goals'].mean()
        avg_a = df['away_goals'].mean()
        df['lh_pred'] = avg_h; df['la_pred'] = avg_a
        try:
            h_roll = df.groupby('home')['home_goals'].transform(lambda x: x.shift().expanding().mean())
            a_roll = df.groupby('away')['away_goals'].transform(lambda x: x.shift().expanding().mean())
            df['lh_pred'] = h_roll.fillna(avg_h)
            df['la_pred'] = a_roll.fillna(avg_a)
        except: pass
    return df

def fit_params_mle(df):
    if df.empty: return {"success": False}
    try:
        lh_arr = df['lh_pred'].values.astype(np.float64)
        la_arr = df['la_pred'].values.astype(np.float64)
        h_arr = df['home_goals'].values.astype(np.int32)
        a_arr = df['away_goals'].values.astype(np.int32)
    except: return {"success": False}
    def nll_func(params):
        lam3, rho, ha = params
        if not (0<=lam3<=0.5 and -0.3<=rho<=0.3 and 0.8<=ha<=1.6): return 1e9
        return compute_batch_nll(lh_arr, la_arr, h_arr, a_arr, lam3, rho, ha)
    res = minimize(nll_func, [0.1, -0.1, 1.15], method='Nelder-Mead', tol=1e-3)
    return {"lam3": res.x[0], "rho": res.x[1], "home_adv": res.x[2], "success": res.success}

def run_kalman_tracking(df):
    class SimpleKalmanFilter:
        def __init__(self, r=1.0): self.x=r; self.P=1.0; self.Q=0.05; self.R=1.0
        def predict(self): self.P+=self.Q; return self.x
        def update(self, z):
            K = self.P/(self.P+self.R)
            self.x += K*(z-self.x)
            self.P *= (1-K)
            return self.x
    if df.empty: return pd.DataFrame(), {}
    teams = set(df['home']).union(set(df['away']))
    ratings = {t: SimpleKalmanFilter() for t in teams}
    hist = []
    for _, r in df.iterrows():
        h, a = r['home'], r['away']
        rh, ra = ratings[h].predict(), ratings[a].predict()
        n_h, n_a = ratings[h].update(r['home_goals']), ratings[a].update(r['away_goals'])
        hist.append({'home': h, 'away': a, 'h_rating': n_h, 'a_rating': n_a})
    return pd.DataFrame(hist), ratings

# [V39/40 è¦–è¦ºåŒ–å·¥å…·]
def plot_score_heatmap(M):
    if not HAS_PLOTLY: return None
    limit = 6
    labels = [str(i) for i in range(limit)]
    fig = px.imshow(M[:limit, :limit], 
                    labels=dict(x="å®¢éšŠé€²çƒ", y="ä¸»éšŠé€²çƒ", color="æ©Ÿç‡"),
                    x=labels, y=labels, text_auto='.1%')
    fig.update_layout(title="æ³¢è†½æ©Ÿç‡ç†±åŠ›åœ–", width=500, height=400)
    return fig

def plot_sensitivity_surface(lh_base, la_base, lam3, rho, max_g):
    if not HAS_PLOTLY: return None
    x = np.linspace(0.8, 1.2, 10)
    y = np.linspace(0.8, 1.2, 10)
    X, Y = np.meshgrid(x, y)
    Z = np.zeros_like(X)
    for i in range(10):
        for j in range(10):
            l1, l2 = lh_base * X[i,j], la_base * Y[i,j]
            p = 0
            for h in range(max_g):
                for a in range(h):
                    p += math.exp(biv_poisson_logpmf_fast(h, a, max(0.01, l1-lam3), max(0.01, l2-lam3), lam3))
            Z[i,j] = p
    fig = go.Figure(data=[go.Surface(z=Z, x=X, y=Y)])
    fig.update_layout(title="ä¸»å‹æ©Ÿç‡æ•æ„Ÿåº¦", scene=dict(xaxis_title="ä¸»éšŠä¿‚æ•¸", yaxis_title="å®¢éšŠä¿‚æ•¸", zaxis_title="ä¸»å‹ç‡"))
    return fig

def plot_radar_chart(lh, la):
    if not HAS_PLOTLY: return None
    def normalize(val): return min(100, max(20, val * 40))
    categories = ['é€²æ”»èƒ½åŠ›', 'é˜²å®ˆå£“è¿«', 'è¿‘æœŸç‹€æ…‹', 'ä¸»å®¢å„ªå‹¢', 'é‹æ°£æŒ‡æ•¸']
    fig = go.Figure()
    fig.add_trace(go.Scatterpolar(r=[normalize(lh), normalize(1/la), 75, 80, 50], theta=categories, fill='toself', name='ä¸»éšŠ'))
    fig.add_trace(go.Scatterpolar(r=[normalize(la), normalize(1/lh), 65, 40, 50], theta=categories, fill='toself', name='å®¢éšŠ'))
    fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 100])), showlegend=True, title="çƒéšŠæˆ°åŠ›é›·é”")
    return fig

def plot_calendar_heatmap(df_bets):
    if not HAS_PLOTLY or df_bets.empty: return None
    if "Date" not in df_bets.columns or "PnL" not in df_bets.columns: return None
    df_bets['DateObj'] = pd.to_datetime(df_bets['Date']).dt.date
    daily = df_bets.groupby('DateObj')['PnL'].sum().reset_index()
    fig = px.density_heatmap(daily, x="DateObj", y="PnL", title="ç²åˆ©æ—¥æ›†ç†±åŠ›åœ–", nbinsx=20)
    return fig

# =========================
# 5. UI (V40.6 Grand Fix)
# =========================
st.set_page_config(page_title="Sniper V40.6", page_icon="ğŸ§¿", layout="wide")
st.markdown("<style>.metric-box { background-color: #f0f2f6; padding: 10px; border-radius: 8px; text-align: center; } .stProgress > div > div > div > div { background-color: #4CAF50; }</style>", unsafe_allow_html=True)

# åˆå§‹åŒ–
ptrader = PaperTradingSystem()
if "cart" not in st.session_state: st.session_state.cart = []

with st.sidebar:
    st.title("ğŸ§¿ Sniper V40.6")
    st.caption("Grand Fix Edition")
    if HAS_NUMBA: st.success("âš¡ Numba åŠ é€Ÿï¼šå·²å•Ÿå‹•")
    else: st.warning("âš ï¸ Numba åŠ é€Ÿï¼šæœªå•Ÿå‹•")
    
    # æˆ°æƒ…å®¤
    n_bets, t_stake, t_pnl = ptrader.get_stats()
    st.markdown("### ğŸï¸ æˆ°æƒ…å®¤")
    col_w1, col_w2 = st.columns(2)
    col_w1.metric("æ¨¡æ“¬æœ¬é‡‘", "$10,000")
    col_w2.metric("ç´¯ç©æç›Š", f"${t_pnl:.1f}", delta=f"{t_pnl/100:.1f}%")
    st.metric("ä»Šæ—¥æ³¨å–® / ç¸½é¡", f"{len(st.session_state.cart)} / {n_bets}", f"${t_stake:.0f}")
    
    st.divider()
    app_mode = st.radio("åŠŸèƒ½æ¨¡å¼ï¼š", ["ğŸ¯ å–®å ´æ·±åº¦é æ¸¬", "ğŸ›¡ï¸ é¢¨éšªå°æ²–å¯¦é©—å®¤", "ğŸ”§ åƒæ•¸æ ¡æ­£å¯¦é©—å®¤", "ğŸ“ˆ å¯¦æˆ°ç¸¾æ•ˆå›é¡§", "ğŸ“š åŠ‡æœ¬æŸ¥è©¢"])
    st.divider()
    
    # è³¼ç‰©è»Š
    with st.expander(f"ğŸ›’ å¾…ç¢ºèªæ³¨å–® ({len(st.session_state.cart)})", expanded=False):
        if st.session_state.cart:
            for i, bet in enumerate(st.session_state.cart):
                st.write(f"{i+1}. {bet['sel']} @ {bet['odds']} (${bet['stake']})")
            if st.button("âœ… ä¸€éµä¸‹æ³¨"):
                for bet in st.session_state.cart: ptrader.add_bet(bet['sel'], bet['odds'], bet['stake'])
                st.session_state.cart = []
                st.success("ä¸‹æ³¨æˆåŠŸï¼")
                st.rerun()
            if st.button("ğŸ—‘ï¸ æ¸…ç©º"):
                st.session_state.cart = []
                st.rerun()
        else: st.info("æš«ç„¡æ³¨å–®")

    with st.expander("ğŸ› ï¸ é€²éšåƒæ•¸", expanded=False):
        unit_stake = st.number_input("å–®æ³¨æœ¬é‡‘", 10, 10000, 100)
        nb_alpha = st.slider("Alpha", 0.05, 0.25, 0.12)
        use_biv = st.toggle("é›™è®Šé‡", True)
        use_dc = st.toggle("Dixon-Coles", True)
        lam3_in = st.number_input("Lambda 3", 0.0, 0.5, 0.15)
        rho_in = st.number_input("Rho", -0.3, 0.3, -0.13)
        ha_in = st.number_input("Home Adv", 0.8, 1.6, 1.15)
        risk_scale = st.slider("Kelly ä¿‚æ•¸", 0.1, 1.0, 0.3)
        show_unc = st.toggle("é¡¯ç¤ºå€é–“", True)

if app_mode == "ğŸ¯ å–®å ´æ·±åº¦é æ¸¬":
    st.header("ğŸ¯ å–®å ´æ·±åº¦é æ¸¬ (V40)")
    if "analysis_results" not in st.session_state: st.session_state.analysis_results = None
    
    t1, t2 = st.tabs(["ğŸ“‹ è²¼ä¸Š JSON", "ğŸ“‚ ä¸Šå‚³ JSON"])
    inp = None
    with t1:
        txt = st.text_area("JSON Input", height=100)
        if txt: 
            try: inp = json.loads(txt)
            except: st.error("Error")
    with t2:
        f = st.file_uploader("JSON File", type=['json'])
        if f: inp = json.load(f)

    if st.button("ğŸš€ åŸ·è¡Œåˆ†æ", type="primary") and inp:
        eng = SniperAnalystLogic(inp, 9, nb_alpha, lam3_in, rho_in, ha_in)
        lh, la, w = eng.calc_lambda()
        M, probs = eng.build_matrix_v38(lh, la, use_biv, use_dc)
        bonus = eng.get_market_trend_bonus()
        odds = eng.market["1x2_odds"]
        rid = eng.memory.analyze_scenario(lh, la, odds)
        h_dat = eng.memory.recall_experience(rid)
        sens_lv, sens_dr = eng.check_sensitivity(lh, la)
        diff_p = abs(probs["hybrid"]["home"] - probs["market"]["home"])
        conf, reasons = eng.calc_model_confidence(lh, la, diff_p, sens_dr)
        hw, dr, aw, sh, sa = eng.run_monte_carlo_vectorized(M)
        
        st.session_state.analysis_results = {
            "eng": eng, "M": M, "lh": lh, "la": la, "w": w,
            "probs": probs, "bonus": bonus, "h_dat": h_dat, "pen": 1.0,
            "conf": conf, "reasons": reasons, "sh": sh, "sa": sa
        }

    if st.session_state.analysis_results:
        res = st.session_state.analysis_results
        eng, M, probs = res["eng"], res["M"], res["probs"]
        
        st.markdown("### ğŸ” æˆ°è¡“å„€è¡¨æ¿")
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("ä¸»éšŠé æœŸ", f"{res['lh']:.2f}")
        c2.metric("å®¢éšŠé æœŸ", f"{res['la']:.2f}")
        c3.metric("æ¨¡å‹ä¸»å‹", f"{probs['hybrid']['home']:.1%}")
        c4.metric("ä¿¡å¿ƒ", f"{res['conf']:.0%}")

        t_val, t_ai, t_vis, t_sim, t_sand = st.tabs(["ğŸ’° åƒ¹å€¼æŠ•è³‡", "ğŸ§  æ™ºèƒ½è£æ±º", "ğŸŒˆ è¦–è¦ºæ´å¯Ÿ", "ğŸ² æ¥µé€Ÿæ¨¡æ“¬", "ğŸ”® çµ‚æ¥µæ²™ç›¤æ¨æ¼”"])
        
        candidates = []
        with t_val:
            st.subheader("ç¨è´ (1x2)")
            r_1x2 = []
            for tag, k in [("ä¸»å‹","home"),("å’Œå±€","draw"),("å®¢å‹","away")]:
                p = probs["hybrid"][k]
                o = eng.market["1x2_odds"][k]
                raw_ev = (p*o - 1)*100 + res["bonus"][k]
                adj_ev = raw_ev * res["conf"]
                var, sharpe = calc_risk_metrics(p, o)
                kelly = calc_risk_adj_kelly(adj_ev, var, risk_scale, p)
                amt = unit_stake * (kelly/100.0)
                r_1x2.append({"é¸é …": tag, "è³ ç‡": o, "æ©Ÿç‡": f"{p:.1%}", "æœŸæœ›å€¼": f"{adj_ev:.1f}%", "å‡±åˆ©å»ºè­°": f"{kelly:.1f}%", "å»ºè­°é‡‘é¡": f"${amt:.0f}"})
                if adj_ev > 0.2: 
                    candidates.append({"pick": tag, "odds": o, "ev": adj_ev, "kelly": kelly, "type": "1x2", "prob": p, "sharpe": sharpe})
            st.dataframe(pd.DataFrame(r_1x2), use_container_width=True)
            
            # [V40.6] äºç›¤å„ªåŒ– - é¡¯ç¤ºã€Œèª°è®“åˆ†ã€
            c_ah, c_ou = st.columns(2)
            with c_ah:
                st.subheader("äºç›¤ (AH)")
                rows_ah = []
                target = eng.market.get("target_odds", 1.90)
                for hcap in eng.market.get("handicaps", [-0.5, 0.5]):
                    raw = eng.ah_ev(M, hcap, target) + res["bonus"]["home"]
                    adj = raw * res["conf"]
                    p_approx = (raw/100+1)/target
                    var, sharpe = calc_risk_metrics(p_approx, target)
                    kel = calc_risk_adj_kelly(adj, var, risk_scale, p_approx)
                    amt = unit_stake * (kel/100.0)
                    
                    # åˆ¤æ–·è®“åˆ†æ–¹
                    if hcap < 0: tag_str = f"ä¸»è®“ {hcap}"
                    elif hcap > 0: tag_str = f"ä¸»å— +{hcap}"
                    else: tag_str = "å¹³æ‰‹ç›¤"
                    
                    rows_ah.append({"ç›¤å£": tag_str, "æ©Ÿç‡": f"{p_approx:.1%}", "æœŸæœ›å€¼": f"{adj:.1f}%", "å‡±åˆ©": f"{kel:.1f}%", "é‡‘é¡": f"${amt:.0f}"})
                    if adj > 0.5: candidates.append({"pick": tag_str, "odds": target, "ev": adj, "kelly": kel, "type": "AH", "prob": p_approx, "sharpe": sharpe})
                st.dataframe(pd.DataFrame(rows_ah), use_container_width=True)
            
            with c_ou:
                st.subheader("å¤§å° (OU)")
                rows_ou = []
                idx_sum = np.add.outer(np.arange(eng.max_g), np.arange(eng.max_g))
                for line in eng.market.get("goal_lines", [2.5]):
                    p_over = float(M[idx_sum > line].sum())
                    raw = (p_over*target - 1)*100
                    adj = raw * res["conf"]
                    var, sharpe = calc_risk_metrics(p_over, target)
                    kel = calc_risk_adj_kelly(adj, var, risk_scale, p_over)
                    amt = unit_stake * (kel/100.0)
                    rows_ou.append({"ç›¤å£": f"å¤§ {line}", "æ©Ÿç‡": f"{p_over:.1%}", "æœŸæœ›å€¼": f"{adj:.1f}%", "å‡±åˆ©": f"{kel:.1f}%", "é‡‘é¡": f"${amt:.0f}"})
                    if adj > 0.5: candidates.append({"pick":f"å¤§ {line}", "odds":target, "ev":adj, "kelly":kel, "type":"OU", "prob": p_over, "sharpe": sharpe})
                st.dataframe(pd.DataFrame(rows_ou), use_container_width=True)
                
            st.divider()
            st.markdown("### ğŸ† æ™ºèƒ½æŠ•è³‡çµ„åˆ")
            if candidates:
                best = sorted(candidates, key=lambda x: x['ev'], reverse=True)
                reco = []
                for p in best:
                    amt = unit_stake * (p['kelly']/100)
                    reco.append({"é¸é …": f"[{p['type']}] {p['pick']}", "è³ ç‡": p['odds'], "æœŸæœ›å€¼": f"{p['ev']:+.1f}%", "å‡±åˆ©%": f"{p['kelly']:.1f}%", "å»ºè­°$": f"${amt:.1f}"})
                st.dataframe(pd.DataFrame(reco), use_container_width=True)
                
                c_cart1, c_cart2 = st.columns([3, 1])
                bet_pick = c_cart1.selectbox("åŠ å…¥è³¼ç‰©è»Š", [f"[{p['type']}] {p['pick']}" for p in best])
                if c_cart2.button("â•"):
                    sel = next(p for p in best if f"[{p['type']}] {p['pick']}" == bet_pick)
                    amt = unit_stake * (sel['kelly']/100)
                    st.session_state.cart.append({"sel": bet_pick, "odds": sel['odds'], "stake": amt})
                    st.success("å·²åŠ å…¥")
                    st.rerun()
            else: st.info("ç„¡æ¨è–¦æ³¨å–®")

        with t_ai:
            st.write("æ¬Šé‡åˆ†æ")
            st.dataframe(pd.DataFrame([probs["model"], probs["market"], probs["hybrid"]], index=["ç´”æ¨¡å‹","å¸‚å ´éš±å«","æ··åˆæ¬Šé‡"]))

        with t_vis:
            st.subheader("ğŸŒˆ è¦–è¦ºæ´å¯Ÿ")
            if HAS_PLOTLY:
                st.plotly_chart(plot_radar_chart(res['lh'], res['la']), use_container_width=True)
                st.divider()
                c_v1, c_v2 = st.columns(2)
                with c_v1: st.plotly_chart(plot_score_heatmap(M), use_container_width=True)
                with c_v2: st.plotly_chart(px.histogram(x=res["sh"], nbins=10, title="ä¸»éšŠé€²çƒ"), use_container_width=True)
                st.plotly_chart(plot_sensitivity_surface(res['lh'], res['la'], lam3_in, rho_in, 9), use_container_width=True)
            else: st.warning("è«‹å®‰è£ Plotly")

        with t_sim:
            hw = np.sum(res["sh"] > res["sa"]) / 500000
            st.metric("MC ä¸»å‹", f"{hw:.1%}")
            ce_res = eng.run_ce_importance_sampling(M, 4.5)
            st.metric("å¤§ 4.5 æ©Ÿç‡", f"{ce_res['est']:.2%}")

        with t_sand:
            st.subheader("ğŸ”® å…¨åŸŸæ²™ç›¤æ¨æ¼”")
            st.info("èª¿æ•´åƒæ•¸ï¼Œå³æ™‚é è¦½è®ŠåŒ–ã€‚")
            sc1, sc2, sc3 = st.columns(3)
            mod_ah = sc1.slider("ä¸»éšŠé€²æ”»", 0.5, 1.5, 1.0, 0.05)
            mod_da = sc1.slider("å®¢éšŠé˜²å®ˆ", 0.5, 1.5, 1.0, 0.05)
            mod_aa = sc2.slider("å®¢éšŠé€²æ”»", 0.5, 1.5, 1.0, 0.05)
            mod_dh = sc2.slider("ä¸»éšŠé˜²å®ˆ", 0.5, 1.5, 1.0, 0.05)
            luck = sc3.slider("é‹æ°£åå·®", 0.8, 1.2, 1.0, 0.05)
            red = sc3.checkbox("ä¸»éšŠç´…ç‰Œ")
            
            lh_n = res['lh'] * mod_ah * mod_da * luck
            la_n = res['la'] * mod_aa * mod_dh * luck
            if red: lh_n *= 0.4; la_n *= 1.3
            
            st.write(f"èª¿æ•´å¾Œ: ä¸» {lh_n:.2f} | å®¢ {la_n:.2f}")
            M_n, _ = eng.build_matrix_v38(lh_n, la_n, use_biv, use_dc)
            ph_n = float(np.sum(np.tril(M_n,-1)))
            
            c_r1, c_r2 = st.columns(2)
            c_r1.metric("æ–°ä¸»å‹ç‡", f"{ph_n:.1%}")
            o_h = eng.market["1x2_odds"]["home"]
            nev = (ph_n*o_h-1)*100
            c_r2.metric("æ–° EV", f"{nev:.1f}%", delta_color="normal" if nev>0 else "inverse")

elif app_mode == "ğŸ›¡ï¸ é¢¨éšªå°æ²–å¯¦é©—å®¤":
    st.title("ğŸ›¡ï¸ é¢¨éšªå°æ²–å¯¦é©—å®¤")
    # [V40.6] æ¢å¾©å®Œæ•´åŠŸèƒ½èˆ‡ä¸­æ–‡åŒ–
    tab_arb, tab_lay, tab_port = st.tabs(["âš¡ 1x2 å¥—åˆ©", "ğŸ“‰ äº¤æ˜“æ‰€å°æ²–", "ğŸ“Š æ™ºèƒ½çµ„åˆå„ªåŒ–"])
    
    with tab_arb:
        c1, c2, c3 = st.columns(3)
        o1 = c1.number_input("ä¸»å‹è³ ç‡", 2.0); o2 = c2.number_input("å’Œå±€è³ ç‡", 3.0); o3 = c3.number_input("å®¢å‹è³ ç‡", 4.0)
        inv = 1/o1+1/o2+1/o3
        if inv<1: st.success(f"ç™¼ç¾å¥—åˆ©æ©Ÿæœƒ! ROI: {1/inv-1:.1%}")
        else: st.info(f"ç„¡å¥—åˆ©ç©ºé–“ (Book: {inv:.2%})")

    with tab_lay:
        c1, c2 = st.columns(2)
        b_o = c1.number_input("Back è³ ç‡", 1.01, 10.0, 2.5)
        stake = c1.number_input("Back æœ¬é‡‘", 10, 1000, 100)
        l_o = c2.number_input("Lay è³ ç‡", 1.01, 10.0, 2.6)
        comm = c2.number_input("ä½£é‡‘ %", 0.0, 5.0, 2.0)/100
        if l_o>1:
            lay_s = (stake*b_o)/(l_o-comm)
            st.metric("å»ºè­° Lay é‡‘é¡", f"${lay_s:.2f}")

    with tab_port:
        if st.session_state.get("analysis_results"):
            res = st.session_state.analysis_results
            sh, sa = res["sh"], res["sa"]
            eng = res["eng"]
            if st.button("âš¡ è¨ˆç®—æœ€ä½³é…ç½®"):
                cands = [{"name":"ä¸»å‹","odds":eng.market["1x2_odds"]["home"],"cond":sh>sa}, {"name":"å’Œå±€","odds":eng.market["1x2_odds"]["draw"],"cond":sh==sa}, {"name":"å¤§2.5","odds":1.9,"cond":(sh+sa)>2.5}]
                pay = np.zeros((500000,3))
                for i,c in enumerate(cands): pay[:,i] = np.where(c["cond"], c["odds"]-1, -1)
                mu, sigma = pay.mean(axis=0), np.cov(pay, rowvar=False)
                cons = ({'type':'eq','fun':lambda w: sum(w)-1})
                opt = minimize(lambda w: -(np.dot(w,mu)-np.dot(w.T,np.dot(sigma,w))), [0.33]*3, bounds=[(0,1)]*3, constraints=cons)
                for i,w in enumerate(opt.x): st.metric(cands[i]["name"], f"{w:.1%}")
                
                ret = np.dot(opt.x, mu)*100
                st.markdown(f"""<div style='background:#f0f2f6;padding:10px;color:black'>
                <b>é¦–å¸­åˆ†æå¸«:</b> é æœŸå›å ± {ret:.2f}%ã€‚å»ºè­° {"åˆ†æ•£é…ç½®ä»¥é™ä½æ³¢å‹•" if max(opt.x)<0.7 else "é›†ä¸­å–®æ‰“é«˜åƒ¹å€¼é¸é …"}ã€‚</div>""", unsafe_allow_html=True)
        else: st.warning("è«‹å…ˆåŸ·è¡Œå–®å ´é æ¸¬")

elif app_mode == "ğŸ”§ åƒæ•¸æ ¡æ­£å¯¦é©—å®¤":
    st.header("ğŸ”§ åƒæ•¸æ ¡æ­£")
    files = st.file_uploader("ä¸Šå‚³ CSV/Excel", type=['csv','xlsx'], accept_multiple_files=True)
    if files:
        dfs = [preprocess_uploaded_data(pd.read_csv(f) if f.name.endswith('.csv') else pd.read_excel(f)) for f in files]
        full = pd.concat([d for d in dfs if not d.empty])
        if st.button("âš¡ MLE"):
            r = fit_params_mle(full)
            if r["success"]: st.success(f"Lam3={r['lam3']:.2f}, Rho={r['rho']:.2f}, HA={r['home_adv']:.2f}")

# [MODE 4: å¯¦æˆ°ç¸¾æ•ˆå›é¡§ (Fixed Crash)]
elif app_mode == "ğŸ“ˆ å¯¦æˆ°ç¸¾æ•ˆå›é¡§":
    st.title("ğŸ“ˆ å¯¦æˆ°ç¸¾æ•ˆå›é¡§")
    df = ptrader.load_bets()
    
    if not df.empty:
        st.markdown("### ğŸ“ æ³¨å–®ç®¡ç† (ç›´æ¥é»æ“Šè¡¨æ ¼ä¿®æ”¹)")
        # [V40.6 Fix] Corrected SelectboxColumn
        edited_df = st.data_editor(
            df,
            column_config={
                "Result": st.column_config.SelectboxColumn(
                    "æ¯”è³½çµæœ",
                    width="medium",
                    options=["Pending", "Win", "Lose", "Void"],
                    required=True,
                ),
                "PnL": st.column_config.NumberColumn(
                    "æç›Š (PnL)",
                    format="$%.1f",
                    disabled=True 
                )
            },
            num_rows="dynamic",
            use_container_width=True
        )
        
        if st.button("ğŸ’¾ ä¿å­˜è®Šæ›´ & çµç®—æç›Š"):
            ptrader.save_bets(edited_df)
            st.success("å·²æ›´æ–°æç›Šç‹€æ…‹ï¼")
            st.rerun()
            
        st.divider()
        if HAS_PLOTLY and "PnL" in df.columns:
            st.subheader("ğŸ’° è³‡é‡‘æˆé•·æ›²ç·š")
            df["CumPnL"] = df["PnL"].cumsum()
            st.plotly_chart(px.line(df, x="Date", y="CumPnL", markers=True), use_container_width=True)
            st.subheader("ğŸ“… ç²åˆ©æ—¥æ›†")
            st.plotly_chart(plot_calendar_heatmap(df), use_container_width=True)
    else:
        st.info("å°šç„¡æ¨¡æ“¬æ³¨å–®ã€‚è«‹åœ¨ã€Œå–®å ´æ·±åº¦é æ¸¬ã€ä¸­åŠ å…¥æ³¨å–®ã€‚")

elif app_mode == "ğŸ“š åŠ‡æœ¬æŸ¥è©¢":
    st.dataframe(pd.DataFrame([{"Name":v["name"],"ROI":v["roi"]} for k,v in RegimeMemory().history_db.items()]))
